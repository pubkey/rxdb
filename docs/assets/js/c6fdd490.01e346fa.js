"use strict";(globalThis.webpackChunkrxdb=globalThis.webpackChunkrxdb||[]).push([[4141],{7291:(e,r,s)=>{s.r(r),s.d(r,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"rx-server-scaling","title":"RxServer Scaling - Vertical or Horizontal","description":"Discover vertical and horizontal techniques to boost RxServer. Learn multiple processes, worker threads, and replication for limitless performance.","source":"@site/docs/rx-server-scaling.md","sourceDirName":".","slug":"/rx-server-scaling.html","permalink":"/rx-server-scaling.html","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"RxServer Scaling - Vertical or Horizontal","slug":"rx-server-scaling.html","description":"Discover vertical and horizontal techniques to boost RxServer. Learn multiple processes, worker threads, and replication for limitless performance."},"sidebar":"tutorialSidebar","previous":{"title":"RxServer","permalink":"/rx-server.html"},"next":{"title":"Transactions Conflicts Revisions","permalink":"/transactions-conflicts-revisions.html"}}');var a=s(4848),n=s(8453);const i={title:"RxServer Scaling - Vertical or Horizontal",slug:"rx-server-scaling.html",description:"Discover vertical and horizontal techniques to boost RxServer. Learn multiple processes, worker threads, and replication for limitless performance."},o="Scaling the RxServer",l={},c=[{value:"Vertical Scaling",id:"vertical-scaling",level:2},{value:"Run multiple JavaScript processes",id:"run-multiple-javascript-processes",level:3},{value:"Using workers to split up the load",id:"using-workers-to-split-up-the-load",level:3},{value:"Use an in-memory storage at the user facing level",id:"use-an-in-memory-storage-at-the-user-facing-level",level:3},{value:"Horizontal Scaling",id:"horizontal-scaling",level:2},{value:"Single Datastore with multiple branches",id:"single-datastore-with-multiple-branches",level:3},{value:"Moving the branches to &quot;the edge&quot;",id:"moving-the-branches-to-the-edge",level:3},{value:"Replicate Databases for Microservices",id:"replicate-databases-for-microservices",level:3},{value:"Use a self-scaling RxStorage",id:"use-a-self-scaling-rxstorage",level:3}];function h(e){const r={a:"a",code:"code",figure:"figure",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",span:"span",strong:"strong",...(0,n.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.header,{children:(0,a.jsx)(r.h1,{id:"scaling-the-rxserver",children:"Scaling the RxServer"})}),"\n",(0,a.jsxs)(r.p,{children:["The ",(0,a.jsx)(r.a,{href:"/rx-server.html",children:"RxDB Server"})," run in JavaScript and JavaScript runs on a single process on the operating system. This can make the CPU performance limit to be the main bottleneck when serving requests to your users. To mitigate that problem, there are a wide range of methods to scale up the server so that it can serve more requests at the same time faster."]}),"\n",(0,a.jsx)(r.h2,{id:"vertical-scaling",children:"Vertical Scaling"}),"\n",(0,a.jsx)(r.p,{children:'Vertical Scaling aka "scaling up" has the goal to get more power out of a single server by utilizing more of the servers compute. Vertical scaling should be the first step when you decide it is time to scale.'}),"\n",(0,a.jsx)(r.h3,{id:"run-multiple-javascript-processes",children:"Run multiple JavaScript processes"}),"\n",(0,a.jsxs)(r.p,{children:["To utilize more compute power of your server, the first step is to scale vertically by running the RxDB server on ",(0,a.jsx)(r.strong,{children:"multiple processes"})," in parallel.\nRxDB itself is already build to support multiInstance-usage on the client, like when the user has opened multiple browser tabs at once. The same method works also on the server side in Node.js. You can spawn multiple JavaScript processes that use the same ",(0,a.jsx)(r.a,{href:"/rx-database.html",children:"RxDatabase"})," and the instances will automatically communicate with each other and distribute their data and events with the ",(0,a.jsx)(r.a,{href:"https://github.com/pubkey/broadcast-channel",children:"BroadcastChannel"}),".\nBy default the ",(0,a.jsx)(r.a,{href:"/rx-database.html#multiinstance",children:"multiInstance param"})," is set to ",(0,a.jsx)(r.code,{children:"true"})," when calling ",(0,a.jsx)(r.code,{children:"createRxDatabase()"}),", so you do not have to change anything. To make all processes accessible through the same endpoint, you can put a load-balancer like ",(0,a.jsx)(r.a,{href:"https://nginx.org/en/docs/http/load_balancing.html",children:"nginx"})," in front of them."]}),"\n",(0,a.jsx)(r.h3,{id:"using-workers-to-split-up-the-load",children:"Using workers to split up the load"}),"\n",(0,a.jsxs)(r.p,{children:["Another way to increases the server capacity is to put the storage into a ",(0,a.jsx)(r.a,{href:"/rx-storage-worker.html",children:"Worker thread"}),' so that the "main" thread with the webserver can handle more requests. This might be easier to set up compared to using multiple JavaScript processes and a load balancer.']}),"\n",(0,a.jsx)(r.h3,{id:"use-an-in-memory-storage-at-the-user-facing-level",children:"Use an in-memory storage at the user facing level"}),"\n",(0,a.jsxs)(r.p,{children:["Another way to serve more requests to your end users, is to use an ",(0,a.jsx)(r.a,{href:"/rx-storage-memory.html",children:"in-memory"})," storage that has the ",(0,a.jsx)(r.a,{href:"/rx-storage-performance.html",children:"best"})," read- and write performance. It outperforms persistent storages by a factor of 10x.\nSo instead of directly serving requests from the persistence layer, you add an in-memory layer on top of that. You could either do a ",(0,a.jsx)(r.a,{href:"/replication.html",children:"replication"})," from your memory database to the persistent one, or you use the ",(0,a.jsx)(r.a,{href:"/rx-storage-memory-mapped.html",children:"memory mapped"})," storage which has this build in."]}),"\n",(0,a.jsx)(r.figure,{"data-rehype-pretty-code-figure":"",children:(0,a.jsx)(r.pre,{style:{backgroundColor:"var(--shiki-background)",color:"var(--shiki-foreground)"},tabIndex:"0","data-language":"ts","data-theme":"css-variables",children:(0,a.jsxs)(r.code,{"data-language":"ts","data-theme":"css-variables",style:{display:"grid"},children:[(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"import"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:" { getRxStorageMemory } "}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"from"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'rxdb/plugins/storage-memory'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:";"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"import"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:" { replicateRxCollection } "}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"from"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'rxdb/plugins/replication'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:";"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"import"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:" { getRxStorageFilesystemNode } "}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"from"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'rxdb-premium/plugins/storage-filesystem-node'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:";"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"import"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:" { getMemoryMappedRxStorage } "}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"from"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'rxdb-premium/plugins/storage-memory-mapped'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:";"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"const"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-constant)"},children:" myRxDatabase"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:" ="}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:" await"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:" createRxDatabase"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"({"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"    name"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'mydb'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-punctuation)"},children:","})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"    storage"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:" getMemoryMappedRxStorage"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"({"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"        storage"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:" getRxStorageFilesystemNode"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"({"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"            basePath"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-constant)"},children:" path"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:".join"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"(__dirname"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-punctuation)"},children:","}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-string-expression)"},children:" 'my-database-folder'"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:")"})]}),"\n",(0,a.jsx)(r.span,{"data-line":"",children:(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"        })"})}),"\n",(0,a.jsx)(r.span,{"data-line":"",children:(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"    })"})}),"\n",(0,a.jsx)(r.span,{"data-line":"",children:(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"});"})}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"await"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-constant)"},children:" myDatabase"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:".addCollections"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"({"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-comment)"},children:"/* ... */"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"});"})]}),"\n",(0,a.jsx)(r.span,{"data-line":"",children:" "}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:"const"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-constant)"},children:" myServer"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:" ="}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:" await"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-function)"},children:" startRxServer"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"({"})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"    database"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:" myRxDatabase"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-punctuation)"},children:","})]}),"\n",(0,a.jsxs)(r.span,{"data-line":"",children:[(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"    port"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,a.jsx)(r.span,{style:{color:"var(--shiki-token-constant)"},children:" 443"})]}),"\n",(0,a.jsx)(r.span,{"data-line":"",children:(0,a.jsx)(r.span,{style:{color:"var(--shiki-foreground)"},children:"});"})})]})})}),"\n",(0,a.jsxs)(r.p,{children:["But notice that you have to check your persistence requirements. When a write happens to the memory layer and the server crashes while it has not persisted, in rare cases the write operation might get lost. You can remove that risk by setting ",(0,a.jsx)(r.code,{children:"awaitWritePersistence: true"})," on the  ",(0,a.jsx)(r.a,{href:"/rx-storage-memory-mapped.html",children:"memory mapped storage"})," settings."]}),"\n",(0,a.jsx)(r.h2,{id:"horizontal-scaling",children:"Horizontal Scaling"}),"\n",(0,a.jsx)(r.p,{children:"To scale the RxDB Server above a single physical hardware unit, there are different solutions where the decision depends on the exact use case."}),"\n",(0,a.jsx)(r.h3,{id:"single-datastore-with-multiple-branches",children:"Single Datastore with multiple branches"}),"\n",(0,a.jsxs)(r.p,{children:['The most common way to use multiple servers with RxDB is to split up the server into a tree with a root "datastore" and multiple "branches". The datastore contains the persisted data and only servers as a replication endpoint for the branches. The branches themself will replicate data to and from the datastore and server requests to the end users.\nThis is mostly useful on read-heavy applications because reads will directly run on the branches without ever reaching the main datastore and you can always add more branches to ',(0,a.jsx)(r.strong,{children:"scale up"}),'. Even adding additional layers of "datastores" is possible so the tree can grow (or shrink) with the demand.']}),"\n",(0,a.jsx)("p",{align:"center",children:(0,a.jsx)("img",{src:"./files/server-scaling-tree.png",alt:"Server Scaling Tree",width:"320",class:"img-padding"})}),"\n",(0,a.jsx)(r.h3,{id:"moving-the-branches-to-the-edge",children:'Moving the branches to "the edge"'}),"\n",(0,a.jsxs)(r.p,{children:['Instead of running the "branches" of the tree on the same physical location as the datastore, it often makes sense to move the branches into a datacenter near the end users. Because the RxDB ',(0,a.jsx)(r.a,{href:"/replication.html",children:"replication algorithm"})," is made to work with slow and even partially offline users, using it for physically separated servers will work the same way. Latency is not that important because writes and reads will not decrease performance by blocking each other and the replication can run in the background without blocking other servers during transaction."]}),"\n",(0,a.jsx)(r.h3,{id:"replicate-databases-for-microservices",children:"Replicate Databases for Microservices"}),"\n",(0,a.jsxs)(r.p,{children:["If your application is build with a ",(0,a.jsx)(r.a,{href:"https://en.wikipedia.org/wiki/Microservices",children:"microservice architecture"})," and your microservices are also build in Node.js, you can scale the database horizontally by moving the database into the microservices and use the ",(0,a.jsx)(r.a,{href:"/replication.html",children:"RxDB replication"}),' to do a realtime sync between the microservices and a main "datastore" server. The "datastore" server would then only handle the replication requests or do some additional things like logging or ',(0,a.jsx)(r.a,{href:"/backup.html",children:"backups"}),". The compute for reads and writes will then mainly be done on the microservices themself. This simplifies setting up more and more microservices without decreasing the performance of the whole system."]}),"\n",(0,a.jsx)(r.h3,{id:"use-a-self-scaling-rxstorage",children:"Use a self-scaling RxStorage"}),"\n",(0,a.jsxs)(r.p,{children:["An alternative to scaling up the RxDB servers themself, you can also switch to a ",(0,a.jsx)(r.a,{href:"/rx-storage.html",children:"RxStorage"})," which scales up internally. For example the ",(0,a.jsx)(r.a,{href:"/rx-storage-foundationdb.html",children:"FoundationDB storage"})," or ",(0,a.jsx)(r.a,{href:"/rx-storage-mongodb.html",children:"MongoDB"})," can work on top of a cluster that can increase load by adding more servers to itself. With that you can always add more Node.js RxDB processes that connect to the same cluster and server requests from it."]})]})}function d(e={}){const{wrapper:r}={...(0,n.R)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,r,s)=>{s.d(r,{R:()=>i,x:()=>o});var t=s(6540);const a={},n=t.createContext(a);function i(e){const r=t.useContext(n);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(n.Provider,{value:r},e.children)}}}]);