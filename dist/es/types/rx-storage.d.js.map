{"version":3,"file":"rx-storage.d.js","names":[],"sources":["../../../src/types/rx-storage.d.ts"],"sourcesContent":["import type { ChangeEvent } from 'event-reduce-js';\nimport { RxDocumentMeta } from './rx-document';\nimport { MangoQuery } from './rx-query';\nimport { RxJsonSchema } from './rx-schema';\n\n/**\n * The document data how it comes out of the storage instance.\n * Contains all meta data like revision, attachments and deleted-flag.\n */\nexport type RxDocumentData<T> = T & {\n\n    /**\n     * As other NoSQL databases,\n     * RxDB also assumes that no data is finally deleted.\n     * Instead the documents are stored with _deleted: true\n     * which means they will not be returned at queries.\n     */\n    _deleted: boolean;\n\n    /**\n     * The attachments meta data is stored besides to document.\n     */\n    _attachments: {\n        [attachmentId: string]: RxAttachmentData;\n    }\n\n    /**\n     * Contains a revision which is concated with a [height: number]-[identifier: string]\n     * like: '1-3hl4kj3l4kgj34g34glk'.\n     * The revision is used to detect write conflicts and have a document history.\n     * Revisions behave similar to couchdb revisions:\n     * @link https://docs.couchdb.org/en/stable/replication/conflicts.html#revision-tree\n\n    * When writing a document, you must send the correct revision in the previous-field\n     * to make sure that you do not cause a write conflict.\n     * The revision of the 'new' document-field must be created, for example via util.createRevision().\n     * Any revision that matches the [height]-[hash] format can be used.\n     */\n    _rev: string;\n\n    /**\n     * RxDB specific meta data of the document.\n     * TODO in RxDB version 12 we introduced the _meta field.\n     * But for easier migration, _deleted, _rev etc. are still at the root level\n     * of the document.\n     * In the next major release 13 we should move these values into the _meta field.\n     */\n    _meta: RxDocumentMeta;\n}\n\nexport type RxDocumentDataById<RxDocType> = {\n    [documentId: string]: RxDocumentData<RxDocType>;\n}\n\n/**\n * The document data how it is send to the\n * storage instance to save it.\n */\nexport type RxDocumentWriteData<T> = RxDocumentData<T> & {\n    _attachments: {\n        /**\n         * To create a new attachment, set the write data\n         * To delete an attachment, leave it out on the _attachments property.\n         * To change an attachment, set the new write data.\n         * To not touch an attachment, just send the stub again\n         * which came out of the storage instance.\n         */\n        [attachmentId: string]: RxAttachmentData | RxAttachmentWriteData;\n    }\n};\n\nexport type WithDeleted<DocType> = DocType & {\n    _deleted: boolean;\n}\n\n/**\n * Send to the bulkWrite() method of a storage instance.\n */\nexport type BulkWriteRow<RxDocType> = {\n    /**\n     * The current document state in the storage engine,\n     * assumed by the application.\n     * Undefined if the document is a new insert.\n     * While with pouchdb we have to practically only provide the previous revision\n     * we here have to send the full previous document data.\n     * The reason is that to get the previous revision you anyway have to get the full\n     * previous document and so it is easier to just send it all to the storage instance.\n     * This will later allow us to use something different then the _rev key for conflict detection\n     * when we implement other storage instances.\n     */\n    previous?: RxDocumentData<RxDocType>,\n    /**\n     * The new document data to be stored in the storage instance.\n     */\n    document: RxDocumentWriteData<RxDocType>\n};\nexport type BulkWriteRowById<RxDocType> = {\n    [documentId: string]: BulkWriteRow<RxDocType>;\n}\n\n\n/**\n * Meta data of the attachment.\n * Created by RxDB, not by the RxStorage.\n */\nexport type RxAttachmentDataMeta = {\n    /**\n     * The digest which is the output of the hash function\n     * from storage.statics.hash(attachment.data)\n     */\n    digest: string;\n    /**\n     * Size of the attachments data\n     */\n    length: number;\n};\n\n/**\n * Meta data of the attachment\n * how it is send to, or comes out of the RxStorage implementation.\n */\nexport type RxAttachmentData = RxAttachmentDataMeta & {\n    /**\n     * Content type like 'plain/text'\n     */\n    type: string;\n}\n\n/**\n * Data which is needed for new attachments\n * that are send from RxDB to the RxStorage implementation.\n */\nexport type RxAttachmentWriteData = RxAttachmentData & {\n    /**\n     * The data of the attachment. As string in base64 format.\n     * In the past we used BlobBuffer internally but it created many\n     * problems because of then we need the full data (for encryption/compression)\n     * so we anyway have to get the string value out of the BlobBuffer.\n     * \n     * Also using BlobBuffer has no performance benefit because in some RxStorage implementations,\n     * like PouchDB, it just keeps the transaction open for longer because the BlobBuffer\n     * has be be read.\n     */\n    data: string;\n}\n\n\n/**\n * Error that can happer per document when\n * RxStorage.bulkWrite() is called\n */\nexport type RxStorageBulkWriteError<RxDocType> = {\n\n    status: number |\n    409 // conflict\n    /**\n     * Before you add any other status code,\n     * check pouchdb/packages/node_modules/pouch-errors/src/index.js\n     * and try to use the same code as PouchDB does.\n     */\n    ;\n\n    /**\n     * set this property to make it easy\n     * to detect if the object is a RxStorageBulkWriteError\n     */\n    isError: true;\n\n    // primary key of the document\n    documentId: string;\n\n    // the original document data that should have been written.\n    writeRow: BulkWriteRow<RxDocType>;\n\n    /**\n     * The error state must contain the\n     * document state in the database.\n     * This ensures that we can continue resolving a conflict\n     * without having to pull the document out of the db first.\n     * Is not set if the error happens on an insert.\n     */\n    documentInDb?: RxDocumentData<RxDocType>;\n}\n\nexport type RxStorageBulkWriteResponse<DocData> = {\n    /**\n     * A map that is indexed by the documentId\n     * contains all succeded writes.\n     */\n    success: RxDocumentDataById<DocData>;\n\n    /**\n     * A map that is indexed by the documentId\n     * contains all errored writes.\n     */\n    error: {\n        [documentId: string]: RxStorageBulkWriteError<DocData>;\n    }\n}\n\nexport type PreparedQuery<DocType> = MangoQuery<DocType> | any;\n\n/**\n * We return a complex object instead of a single array\n * so we are able to add additional fields in the future.\n */\nexport type RxStorageQueryResult<RxDocType> = {\n    // the found documents, sort order is important.\n    documents: RxDocumentData<RxDocType>[];\n}\n\nexport type RxStorageInstanceCreationParams<RxDocType, InstanceCreationOptions> = {\n\n    /**\n     * A string to uniquely identify the instance of the JavaScript object\n     * of the RxDatabase where this RxStorageInstance belongs to.\n     * In most cases you would use RxDatabase.token here.\n     * \n     * This is used so that we can add caching or reuse stuff that belongs to the same RxDatabase.\n     * For example the BroadcastChannel that is used for event propagation between multiple browser tabs\n     * is cached by this token.\n     * \n     * In theory we could just use the databaseName for that. But to make it easier in unit tests\n     * to simulate cross-tab usage, we cannot assume that the databaseName is unique in a single\n     * JavaScript process. Therefore we use the instance token instead.\n     */\n    databaseInstanceToken: string;\n\n\n    databaseName: string;\n    collectionName: string;\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>;\n    options: InstanceCreationOptions;\n    /**\n     * If multiInstance is true, there can be more\n     * then one instance of the database, for example\n     * when multiple browser tabs exist or more then one Node.js\n     * process relies on the same storage.\n     */\n    multiInstance: boolean;\n}\n\nexport type ChangeStreamOptions = {\n\n    /**\n     * Sequence number of the first event to start with.\n     * If you want to get all ongoing events,\n     * first get the latest sequence number and input it here.\n     * \n     * Optional on changeStream,\n     * will start from the newest sequence.\n     */\n    startSequence?: number;\n    /**\n     * limits the amount of results\n     */\n    limit?: number;\n}\n\n/**\n * In the past we handles each RxChangeEvent by its own.\n * But it has been shown that this take way more performance then needed,\n * especially when the events get transfered over a data layer\n * like with WebWorkers or the BroadcastChannel.\n * So we now process events as bulks internally.\n */\nexport type EventBulk<EventType> = {\n    /**\n     * Unique id of the bulk,\n     * used to detect duplicate bulks\n     * that have already been processed.\n     */\n    id: string;\n    events: EventType[];\n}\n\nexport type ChangeStreamEvent<DocType> = ChangeEvent<RxDocumentData<DocType>> & {\n    /**\n     * An integer that is increasing\n     * and unique per event.\n     * Can be used to sort events or get information\n     * about how many events there are.\n     */\n    sequence: number;\n    /**\n     * The value of the primary key\n     * of the changed document\n     */\n    id: string;\n};\n\nexport type RxStorageChangeEvent<DocType> = {\n    /**\n     * Unique identifier for the event.\n     * When another event with the same id appears, it will be skipped.\n     */\n    eventId: string;\n    documentId: string;\n    change: ChangeEvent<DocType>;\n\n    /**\n     * Unix time in milliseconds of when the operation was triggered\n     * and when it was finished.\n     * This is optional because we do not have this time\n     * for events that come from inside of the storage instance.\n     * \n     * TODO do we even need this values?\n     */\n    startTime?: number;\n    endTime?: number;\n}\n"],"mappings":""}